{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Setup and Initial Data Loading\n",
    "\n",
    "    Environment Setup: Ensure all necessary Python libraries are installed (geopandas, rasterio, rioxarray, numpy, skfuzzy, etc.).\n",
    "    Load Grassland Boundary Data: Use geopandas to load the grassland boundary data from a shapefile or other geospatial file format.\n",
    "\n",
    "2. Data Acquisition and Preprocessing\n",
    "\n",
    "    Identify and Acquire Datasets: Based on the grassland boundaries, identify the relevant datasets (soil, elevation, climate) you need.\n",
    "    Data Preprocessing:\n",
    "        Spatial Alignment: Align all raster datasets to the same spatial extent and resolution, ensuring they match the grassland boundary.\n",
    "        Data Cleaning: Handle any missing or anomalous data in your datasets.\n",
    "\n",
    "3. Fuzzy Logic Model Setup\n",
    "\n",
    "    Define Fuzzy Variables: Create fuzzy variables (Antecedents and Consequents) for each environmental factor (e.g., soil pH, elevation) and the output (e.g., habitat suitability).\n",
    "    Define Membership Functions: Assign membership functions (e.g., triangular, trapezoidal) to each fuzzy set within your fuzzy variables.\n",
    "\n",
    "4. Rule Definition\n",
    "\n",
    "    Create Fuzzy Rules: Define the fuzzy logic rules that relate your input variables (environmental factors) to your output variable (habitat suitability).\n",
    "\n",
    "5. Model Integration and Execution\n",
    "\n",
    "    Integrate Spatial Data with Fuzzy Model:\n",
    "        For each pixel or spatial unit in your aligned datasets, extract the necessary values (e.g., soil pH, elevation).\n",
    "        Input these values into your fuzzy logic model to compute habitat suitability.\n",
    "    Run the Model: Use the fuzzy logic system to process the data and output habitat suitability scores.\n",
    "\n",
    "6. Post-processing and Visualization\n",
    "\n",
    "    Generate Output Raster: Convert the habitat suitability scores back into a raster format, aligning it with your original spatial data.\n",
    "    Visualization: Use tools like matplotlib to visualize the habitat suitability across the grassland area.\n",
    "\n",
    "7. Analysis and Interpretation\n",
    "\n",
    "    Interpret Results: Analyze the habitat suitability map to draw conclusions about the most suitable areas for Sorghastrum nutans.\n",
    "    Validation (Optional): If validation data is available, compare your model's output to assess its accuracy.\n",
    "\n",
    "8. Documentation and Reporting\n",
    "\n",
    "    Document the Workflow: Ensure that each step of your process is well-documented.\n",
    "    Prepare a Final Report: Summarize your methodology, findings, and any conclusions or recommendations.\n",
    "\n",
    "Usage of Grassland Boundary\n",
    "\n",
    "    Initial Data Filtering: Use the grassland boundary to filter or clip your environmental datasets right after loading them. This ensures that all subsequent analyses focus only on the relevant areas.\n",
    "    Spatial Analysis: In the model integration step, use the boundary to ensure that habitat suitability is only calculated for areas within the grassland.\n",
    "\n",
    "This structure provides a comprehensive approach to building and executing your fuzzy logic model, ensuring that spatial considerations are integrated effectively with fuzzy logic principles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Envionmentals\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "from glob import glob\n",
    "import pathlib\n",
    "\n",
    "#Third Party\n",
    "import earthpy as et\n",
    "import earthpy.appeears as etapp\n",
    "# import earthpy.earthexplorer as \n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import skfuzzy as fuzz\n",
    "from skfuzzy import control as ctrl\n",
    "# Inlcude rest of modules as needed\n",
    "\n",
    "# Set data directory globals here\n",
    "# data_dir = os.path.join('asset_folder_here')\n",
    "# grassland_path = os.path.join(data_dir, 'grass','path_location_here')\n",
    "# soil_dir = \n",
    "# climate_dir\n",
    "# dem_dir\n",
    "# topo_dir\n",
    "# vectors_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get boundary gdf for clipping\n",
    "# grass_gdf = gpd.read_file(grassland_path)\n",
    "# study_site-gdf = grass_gdf[['SITES HERE']]\n",
    "\n",
    "# Make sure to check crs \n",
    "\n",
    "# Can run through study site gdf as loop later\n",
    "\n",
    "#Plot code here to test geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define import functions here\n",
    "# Check if arrays or downloads already exist for each layer,  if not \n",
    "# download and create array\n",
    "# Merge arrays if necessary \n",
    "\n",
    "    \n",
    "# soils <-- how the hell do I use this dataset? Check readme\n",
    "# elevation <-- DEM from appears\n",
    "# climate <--- check elsa's post\n",
    "# derived topo <-- ask chatgpt + check old project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prune and Harmonization functions here\n",
    "# Clip arrays to boundary layer, make new clipped object \n",
    "# Check if all arrays have same crs, area, and bounds\n",
    "# throw error if not, print values to compare\n",
    "# get rid of unneccesary layers\n",
    "\n",
    "# \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
