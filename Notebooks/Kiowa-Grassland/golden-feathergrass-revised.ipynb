{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Envionmentals\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "from glob import glob\n",
    "import pathlib\n",
    "import json\n",
    "import requests\n",
    "from math import floor, ceil\n",
    "#Third Party\n",
    "import earthpy as et\n",
    "import earthpy.appeears as etapp\n",
    "# import earthpy.earthexplorer as \n",
    "import geopandas as gpd\n",
    "import geoviews as gv\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "import numpy as np\n",
    "import rioxarray as rxr\n",
    "import rioxarray.merge as rxrmerge\n",
    "from shapely.geometry import mapping\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open('settings.json', 'r') as file:\n",
    "    settings = json.load(file)\n",
    "\n",
    "config = settings[0]\n",
    "\n",
    "# Define the base directory for a run\n",
    "run_name = config['study_site']  # You can change this for each run\n",
    "base_dir = os.path.join(\"./\", run_name)\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import geopandas as gpd\n",
    "from pyproj import CRS\n",
    "\n",
    "def get_utm_crs(gdf):\n",
    "    \"\"\"Determine the UTM CRS based on the centroid of a GeoDataFrame.\"\"\"\n",
    "    # Ensure the gdf is in a geographic CRS for accurate centroid calculation\n",
    "    gdf_geographic = gdf.to_crs(epsg=4326)\n",
    "    centroid = gdf_geographic.geometry.unary_union.centroid\n",
    "    lon, lat = centroid.x, centroid.y\n",
    "\n",
    "    # Determine UTM zone\n",
    "    utm_zone = math.floor((lon + 180) / 6) + 1\n",
    "\n",
    "    utm_crs = CRS(f\"EPSG:269{utm_zone:02d}\")  # Northern hemisphere\n",
    "    \n",
    "     \n",
    "    \n",
    "    return utm_crs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get boundary gdf for clipping\n",
    "\n",
    "# Download and load boundary data\n",
    "boundary_config = config['boundary']\n",
    "boundary_gdf = (gpd.read_file(boundary_config['url'])\n",
    "                .to_crs(boundary_config['crs']))\n",
    "\n",
    "# boundary_crs = get_utm_crs(boundary_gdf)\n",
    "# print(boundary_crs)\n",
    "# boundary_gdf = boundary_gdf.to_crs(boundary_crs)\n",
    "\n",
    "\n",
    "\n",
    "study_site_gdf = (boundary_gdf\n",
    "                  .set_index('GRASSLANDN')\n",
    "                  .loc[[config['study_site']]]\n",
    "                  )\n",
    "print(study_site_gdf.crs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gv.tile_sources.EsriNatGeo *\n",
    " gv.Polygons(\n",
    "     boundary_gdf\n",
    "     [boundary_gdf.GRASSLANDN=='Kiowa National Grassland']\n",
    " )\n",
    " )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study_site_gdf.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    raster_dir = os.path.join(base_dir, \n",
    "                              config['data_sources']\n",
    "                              ['soil']['local_path'])\n",
    "\n",
    "raster_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor, ceil\n",
    "\n",
    "\n",
    "def download_soil_data(study_site_gdf, config):\n",
    "    raster_dir = os.path.join(base_dir, \n",
    "                              config['data_sources']\n",
    "                              ['soil']['local_path'])\n",
    "    os.makedirs(raster_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    bounds = study_site_gdf.total_bounds\n",
    "    min_lon, min_lat, max_lon, max_lat = bounds\n",
    "\n",
    "    min_lat, min_lon = floor(min_lat), floor(min_lon)\n",
    "    max_lat, max_lon = ceil(max_lat), ceil(max_lon)\n",
    "\n",
    "    soil = config['data_sources']['soil']\n",
    "    property = soil['property']\n",
    "    stat = soil['stat']\n",
    "    depth = soil['depth']\n",
    "\n",
    "    rasters = []\n",
    "    for lat in range(min_lat, max_lat):\n",
    "        for lon in range(min_lon, max_lon):\n",
    "            polaris_url = (\n",
    "                \"http://hydrology.cee.duke.edu/POLARIS/PROPERTIES/v1.0/\"\n",
    "                \"{property}/{stat}/{depth}/\"\n",
    "                \"lat{min_lat}{max_lat}_lon{min_lon}{max_lon}.tif\").format(\n",
    "                    property=property, \n",
    "                    stat=stat, \n",
    "                    depth=depth,\n",
    "                    min_lat=lat,\n",
    "                    min_lon=lon,\n",
    "                    max_lat=min(lat + 1, max_lat),\n",
    "                    max_lon=min(lon + 1, max_lon))\n",
    "\n",
    "            local_path = os.path.join(raster_dir, f\"soil_data_{lat}_{lon}.tif\")\n",
    "            if not os.path.exists(local_path):\n",
    "                response = requests.get(polaris_url)\n",
    "                if response.status_code == 200:\n",
    "                    with open(local_path, 'wb') as file:\n",
    "                        file.write(response.content)\n",
    "            rasters.append(local_path)\n",
    "\n",
    "    # Merge rasters into a single data array\n",
    "    merged_raster = None\n",
    "    for raster in rasters:\n",
    "        raster_data = rxr.open_rasterio(raster, masked=True).squeeze()\n",
    "        if merged_raster is None:\n",
    "            merged_raster = raster_data\n",
    "        else:\n",
    "            merged_raster = rxrmerge.merge_arrays([merged_raster, raster_data])\n",
    "\n",
    "    # Reproject the raster to match the CRS of the study site GDF if they are different\n",
    "    if merged_raster.rio.crs != study_site_gdf.crs:\n",
    "        merged_raster = merged_raster.rio.reproject(study_site_gdf.crs)\n",
    "\n",
    "    return merged_raster\n",
    "\n",
    "# Usage\n",
    "soil_data = download_soil_data(study_site_gdf, config)\n",
    "soil_da = soil_data.rio.clip_box(*study_site_gdf.total_bounds)\n",
    "soil_da\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def get_srtm_data(study_site_gdf, config):\n",
    "study_site_name = config['study_site']\n",
    "download_key = study_site_name.replace(\"National Grassland\", \"SRTM\").replace(\" \", \"-\")\n",
    "srtm_dir = os.path.join(base_dir, config['data_sources']\n",
    "                        ['elevation']['local_path'])\n",
    "\n",
    "    # Initialize the downloader\n",
    "srtm_downloader = etapp.AppeearsDownloader(\n",
    "    download_key=download_key,\n",
    "    ea_dir=srtm_dir,\n",
    "    product='SRTMGL1_NC.003',\n",
    "    layer='SRTMGL1_DEM',\n",
    "    start_date='02-11-2000',\n",
    "    end_date='02-21-2000',\n",
    "    polygon=study_site_gdf\n",
    "    )\n",
    "\n",
    "    # Download files if they don't already exist\n",
    "if not os.path.exists(srtm_downloader.data_dir):\n",
    "    srtm_downloader.download_files()\n",
    "\n",
    "    # Find all downloaded SRTM files\n",
    "srtm_paths = glob(os.path.join(srtm_downloader.data_dir, '**', '*.tif'), recursive=True)\n",
    "\n",
    "    # Load and merge the SRTM data arrays\n",
    "print(srtm_paths)\n",
    "srtm_da = [rxr.open_rasterio(srtm_path, masked=True).squeeze() for srtm_path in srtm_paths][0]\n",
    "srtm_da = srtm_da.rio.reproject(study_site_gdf.crs)\n",
    "\n",
    "srtm_da\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xrspatial import slope\n",
    "import rioxarray\n",
    "\n",
    "# Ensure srtm_da is loaded correctly\n",
    "if srtm_da is None:\n",
    "    print(\"Error: srtm_da is not loaded correctly.\")\n",
    "else:\n",
    "    # Calculate slope\n",
    "    dem_slope = slope(srtm_da)\n",
    "\n",
    "    # Check if dem_slope is computed correctly\n",
    "    if dem_slope is None:\n",
    "        print(\"Error: Failed to compute slope.\")\n",
    "    else:\n",
    "        # Save the slope data as a new raster file\n",
    "        slope_path = config['data_sources']['elevation']['slope_path']\n",
    "        dem_slope.rio.to_raster(slope_path, driver='GTiff')\n",
    "        print(f\"Slope raster saved to {slope_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get precipiaiton model for CONUS in year 1950\n",
    "maca_url = ('http://thredds.northwestknowledge.net:8080/thredds/ncss/'\n",
    "                'agg_macav2metdata_pr_bcc-csm1-1-m_r1i1p1_historical_1950_2005_CONUS_monthly.nc'\n",
    "                '?var=precipitation'\n",
    "                '&disableLLSubset=on&disableProjSubset=on'\n",
    "                '&horizStride=1'\n",
    "                '&time_start=1950-01-15T00%3A00%3A00Z&time_end=1950-12-15T00%3A00%3A00Z'\n",
    "                '&timeStride=1&accept=netcdf')\n",
    "maca_response = requests.get(maca_url)\n",
    "\n",
    "# Grab the directory path from json\n",
    "climate_path = os.path.join(base_dir, config['data_sources']\n",
    "                            ['climate']['local_path'])\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(climate_path):\n",
    "     os.makedirs(climate_path, exist_ok=True)\n",
    "\n",
    " # Define the full path including the filename\n",
    "maca_path = os.path.join(climate_path, 'maca.nc')\n",
    "\n",
    " # Assuming maca_response is obtained from a requests.get() call\n",
    "maca_response = requests.get(maca_url)\n",
    "\n",
    " # Write the file to the specified directory\n",
    "with open(maca_path, 'wb') as maca_file:\n",
    "    maca_file.write(maca_response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maca_ds = xr.open_dataset(maca_path, engine = 'netcdf4')\n",
    "maca_ds = maca_ds.assign_coords(lon=maca_ds.lon - 360)\n",
    "maca_ds = maca_ds.rio.write_crs(4269)\n",
    "precip_da = maca_ds['precipitation'].mean(\"time\")\n",
    "# precip_da = maca_ds.precipitation.mean(\"time\")\n",
    "precip_da.rio.write_crs(4269, inplace = True)\n",
    "precip_da.rio.set_spatial_dims('lon','lat', inplace = True)\n",
    "\n",
    "maca_ds.precipitation.mean('time').hvplot(rasterize = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_da = precip_da.rio.reproject_match(soil_da)\n",
    "precip_da = precip_da.rio.clip_box(*study_site_gdf.total_bounds)\n",
    "precip_da\n",
    "print(precip_da.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray as rxr\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "def harmonize_rasters(raster_list, reference_raster):\n",
    "    \"\"\"\n",
    "    Harmonize a list of rasters to match the extent, resolution, and CRS of a reference raster.\n",
    "    Only reprojects and resamples rasters if they are not already harmonized.\n",
    "\n",
    "    Parameters:\n",
    "    raster_list (list of xarray.DataArray): List of rasters to be harmonized.\n",
    "    reference_raster (xarray.DataArray): The raster to use as the reference for harmonization.\n",
    "\n",
    "    Returns:\n",
    "    list of xarray.DataArray: List of harmonized rasters.\n",
    "    \"\"\"\n",
    "    harmonized_rasters = []\n",
    "    for raster in raster_list:\n",
    "        # Check if the raster is already harmonized with the reference raster\n",
    "        if (raster.rio.crs == reference_raster.rio.crs and\n",
    "            raster.rio.shape == reference_raster.rio.shape and\n",
    "            raster.rio.transform() == reference_raster.rio.transform()):\n",
    "            # Raster is already harmonized\n",
    "            harmonized_rasters.append(raster)\n",
    "        else:\n",
    "            # Reproject to match CRS of reference raster\n",
    "            reprojected_raster = raster.rio.reproject_match(reference_raster)\n",
    "\n",
    "            # Resample to match resolution of reference raster, using nearest neighbor interpolation\n",
    "            resampled_raster = reprojected_raster.rio.reproject(\n",
    "                reference_raster.rio.crs,\n",
    "                shape=(reference_raster.rio.height, reference_raster.rio.width),\n",
    "                resampling=Resampling.nearest)\n",
    "\n",
    "            harmonized_rasters.append(resampled_raster)\n",
    "\n",
    "    return harmonized_rasters\n",
    "\n",
    "\n",
    "# Now harmonized_rasters[0], harmonized_rasters[1], and harmonized_rasters[2]\n",
    "# correspond to harmonized elevation, slope data, and climate respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming rasters are  xarray.DataArray objects\n",
    "\n",
    "rasters = [soil_da, srtm_da, dem_slope, precip_da]\n",
    "raster_names = ['soil_da', 'srtm_da', 'dem_slope', 'precip_da']\n",
    "# Check if any raster data array is None\n",
    "for raster, name in zip(rasters, raster_names):\n",
    "    if raster is None:\n",
    "        print(f\"Error: {name} is not loaded correctly.\")\n",
    "\n",
    "# If all rasters are loaded correctly, proceed with harmonization\n",
    "if all(raster is not None for raster in rasters):\n",
    "    harmonized_rasters = harmonize_rasters(\n",
    "        [srtm_da, dem_slope, precip_da],\n",
    "        reference_raster=soil_da\n",
    "    )\n",
    "    # Process harmonized rasters\n",
    "else:\n",
    "    print(\"Harmonization skipped due to missing raster data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Create a simple test data array\n",
    "x = np.linspace(0, 10, 100)\n",
    "test_data_array = xr.DataArray(x, dims=[\"x\"])\n",
    "\n",
    "# Define a simple triangular membership function\n",
    "def create_membership_function(data_array, a, b, c):\n",
    "    return xr.where(\n",
    "        (data_array <= a) | (data_array >= c), 0,\n",
    "        xr.where(\n",
    "            data_array <= b,\n",
    "            (data_array - a) / (b - a), \n",
    "            (c - data_array) / (c - b))\n",
    "    )\n",
    "\n",
    "# Apply the membership function to the test data array\n",
    "mf_test = create_membership_function(test_data_array, 3, 5, 7)\n",
    "\n",
    "# Define and apply a simple fuzzy rule\n",
    "def apply_simple_rule(data_array, threshold):\n",
    "    return xr.where(data_array > threshold, 1, 0)\n",
    "\n",
    "# Apply the rule to the membership function result\n",
    "rule_result = apply_simple_rule(mf_test, 0.5)\n",
    "\n",
    "# Print the results\n",
    "print(\"Membership Function Result:\\n\", mf_test)\n",
    "print(\"\\nRule Application Result:\\n\", rule_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_membership_function(data_array, set_config):\n",
    "    set_type = set_config['type']\n",
    "    a, b, c = set_config['params']  # Unpack the parameters directly\n",
    "    if set_type == 'triangular':\n",
    "        return xr.where(\n",
    "            (data_array <= a) | (data_array >= c), 0,\n",
    "            xr.where(\n",
    "                data_array <= b,\n",
    "                (data_array - a) / (b - a), \n",
    "                (c - data_array) / (c - b))\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_membership_functions(variables_data, variables_config):\n",
    "    membership_functions = {}\n",
    "    for var_name, data_array in variables_data.items():\n",
    "        membership_functions[var_name] = {}\n",
    "        for set_name, set_config in variables_config[var_name]['sets'].items():\n",
    "            membership_functions[var_name][set_name] = create_membership_function(data_array, set_config)\n",
    "    return membership_functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your fuzzy logic configuration\n",
    "fuzzy_config = config['fuzzy_logic']\n",
    "\n",
    "# Prepare your data arrays\n",
    "variables_data = {\n",
    "    'soil_pH': soil_da,\n",
    "    'elevation': srtm_da,\n",
    "    'climate': precip_da,\n",
    "    'slope': dem_slope\n",
    "}\n",
    "\n",
    "# Apply fuzzy logic to the entire arrays\n",
    "habitat_suitability = apply_fuzzy_rule(variables_data, \n",
    "                                       fuzzy_config['variables'], \n",
    "                                       fuzzy_config['rules'])\n",
    "\n",
    "\n",
    "# Visualization and further processing...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fuzzy_rules(membership_functions, rules_config):\n",
    "    # Initialize habitat suitability with zeros\n",
    "    reference_mf = next(iter(next(iter(membership_functions.values())).values()))\n",
    "    habitat_suitability = xr.full_like(reference_mf, 0)\n",
    "\n",
    "    # Iterate over each rule\n",
    "    for rule in rules_config:\n",
    "        condition = rule['if']\n",
    "        outcome = rule['then'].split('.')[-1]  # Extract the outcome part\n",
    "\n",
    "        \n",
    "\n",
    "        # Initialize a temporary array for this rule's result\n",
    "        rule_result = xr.full_like(reference_mf, 0)\n",
    "\n",
    "        # Process the condition\n",
    "        for i in range(0, len(condition), 2):\n",
    "            var_set = condition[i].split('.')\n",
    "            mf = membership_functions[var_set[0]][var_set[1]]\n",
    "            print(\"rule_result dimensions:\", rule_result.dims)\n",
    "            print(\"rule_result coordinates:\", rule_result.coords)\n",
    "\n",
    "            print(\"mf dimensions:\", mf.dims)\n",
    "            print(\"mf coordinates:\", mf.coords)\n",
    "            aligned_rule_result, aligned_mf = xr.align(rule_result, mf, join='outer')\n",
    "\n",
    "            print(\"Aligned rule_result dimensions:\", aligned_rule_result.dims)\n",
    "            print(\"Aligned rule_result coordinates:\", aligned_rule_result.coords)\n",
    "\n",
    "            print(\"Aligned mf dimensions:\", aligned_mf.dims)\n",
    "            print(\"Aligned mf coordinates:\", aligned_mf.coords)\n",
    "\n",
    "\n",
    "            if i == 0:\n",
    "                rule_result = mf\n",
    "            else:\n",
    "                if condition[i-1] == 'AND':\n",
    "                    rule_result = xr.where(aligned_rule_result > 0, aligned_mf, 0)\n",
    "                elif condition[i-1] == 'OR':\n",
    "                    rule_result = np.maximum(aligned_rule_result, aligned_mf)\n",
    "\n",
    "        # Apply the outcome to the habitat suitability\n",
    "        if outcome == 'high':\n",
    "            habitat_suitability = np.maximum(habitat_suitability, rule_result * 100)\n",
    "        elif outcome == 'medium':\n",
    "            habitat_suitability = np.maximum(habitat_suitability, rule_result * 50)\n",
    "        elif outcome == 'low':\n",
    "            habitat_suitability = np.maximum(habitat_suitability, rule_result * 25)\n",
    "\n",
    "    return habitat_suitability\n",
    "\n",
    "# Evaluate the fuzzy rules with the full logic\n",
    "habitat_suitability = evaluate_fuzzy_rules(membership_functions, fuzzy_config['rules'])\n",
    "\n",
    "# Print the final habitat suitability result\n",
    "print(\"Habitat Suitability Result:\", habitat_suitability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you know the CRS of habitat_suitability, for example, 'EPSG:4326'\n",
    "habitat_suitability.rio.write_crs(\"EPSG:4269\", inplace=True)\n",
    "\n",
    "# Now, reproject the habitat suitability DataArray to match the CRS of the study site GeoDataFrame\n",
    "habitat_suitability = habitat_suitability.rio.reproject_match(soil_da)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming habitat_suitability is your DataArray and study_site_gdf is your GeoDataFrame\n",
    "import geoviews as gv\n",
    "import geoviews.feature as gf\n",
    "from cartopy import crs as ccrs\n",
    "\n",
    "# Ensure both DataArray and GeoDataFrame are in the same CRS\n",
    "# If they are not, you might need to reproject one of them\n",
    "\n",
    "# Create a plot of the habitat suitability\n",
    "habitat_plot = habitat_suitability.hvplot.image(\n",
    "    x='x', y='y', \n",
    "    cmap='viridis', \n",
    "    width=700, height=400, \n",
    "    colorbar=True, \n",
    "    title='Habitat Suitability Map'\n",
    ")\n",
    "\n",
    "# Create a plot of the study site polygon\n",
    "study_site_plot = study_site_gdf.hvplot(\n",
    "    geo=True, \n",
    "    alpha=0.3,  # Adjust transparency as needed\n",
    "    color='red'\n",
    ")\n",
    "\n",
    "# Overlay the two plots\n",
    "final_plot = habitat_plot\n",
    "\n",
    "# Display the final plot\n",
    "final_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CRS\n",
    "print(habitat_suitability.rio.crs)\n",
    "print(study_site_gdf.crs)\n",
    "\n",
    "# If they are different, reproject one to match the other\n",
    "# For example, if reprojecting the GeoDataFrame to match the DataArray:\n",
    "# habitat_suitability = habitat_suitability.rio.reproject_match(study_site_gdf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earth-analytics-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
